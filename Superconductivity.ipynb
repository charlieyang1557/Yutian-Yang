{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Superconductivity.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charlieyang1557/Yutian-Yang/blob/master/Superconductivity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIF0ku6tm4fj",
        "colab_type": "code",
        "outputId": "1f5cbfab-0ec7-4d99-ccc2-e202ca6df060",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "supercon = pd.read_csv(\"train.csv\")\n",
        "supercon"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-53ae51561396>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msupercon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0msupercon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File train.csv does not exist: 'train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YxYA9pRm4gH",
        "colab_type": "code",
        "outputId": "dc89c407-b9c5-4f4e-eb33-269099d3b801",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "# Compute the correlation matrix\n",
        "corr = supercon.corr()\n",
        "variables = corr[\"critical_temp\"].abs().sort_values(ascending = False).head(16)\n",
        "\n",
        "variable_names = []\n",
        "for index, val in variables.iteritems():\n",
        "  variable_names.append(index)\n",
        "\n",
        "\n",
        "supercon_features = supercon[variable_names]\n",
        "supercon_features"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-dc06bca412b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compute the correlation matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcorr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msupercon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"critical_temp\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'supercon' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-aDYCM4m4gQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corr = supercon_features.corr()\n",
        "new_corr = corr.abs().mean(axis=0)\n",
        "new_corr.sort_values(ascending=False)\n",
        "\n",
        "# range_atomic_radius has the highest correlation with critical temp and other features\n",
        "# the feature atomic radius and Valence seem important because it appears multiple times\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TfInZj0m4ga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "f, ax = plt.subplots(figsize=(11, 9))\n",
        "sns.heatmap(corr, annot=True)\n",
        "plt.show()\n",
        "\n",
        "# wtd_std_ThermalConductivity has the highest postivie correlation with critical temp,\n",
        "# wtd_mean_valence has the highest negative correlation with critical temp\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2uNkPhNm4gg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.boxplot(x=\"number_of_elements\", y=\"critical_temp\", data=supercon_features,  dodge=False)\n",
        "\n",
        "# general trend: if more number of elements, then higher critical temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ocUwsYbm4gn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.pairplot(x_vars=[\"number_of_elements\"], y_vars=[\"critical_temp\"], data=supercon_features, size=7)\n",
        "\n",
        "from numpy.polynomial.polynomial import polyfit\n",
        "b, m = polyfit(supercon_features['number_of_elements'], supercon_features['critical_temp'], 1)\n",
        "\n",
        "plt.plot(supercon_features['number_of_elements'], supercon_features['critical_temp'], '.')\n",
        "plt.plot(supercon_features['number_of_elements'], b + m * supercon_features['number_of_elements'], '-')\n",
        "plt.title('number_of_elements vs. critical_temp')\n",
        "plt.xlabel('number_of_elements')\n",
        "plt.ylabel('critical_temp')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJgnRyd2m4gv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "sns.pairplot(x_vars=[\"wtd_std_ThermalConductivity\"], y_vars=[\"critical_temp\"], data=supercon_features, size=7)\n",
        "\n",
        "from numpy.polynomial.polynomial import polyfit\n",
        "b, m = polyfit(supercon_features['wtd_std_ThermalConductivity'], supercon_features['critical_temp'], 1)\n",
        "\n",
        "plt.plot(supercon_features['wtd_std_ThermalConductivity'], supercon_features['critical_temp'], '.')\n",
        "plt.plot(supercon_features['wtd_std_ThermalConductivity'], b + m * supercon_features['wtd_std_ThermalConductivity'], '-')\n",
        "plt.title('wtd_std_ThermalConductivity vs. critical_temp')\n",
        "plt.xlabel('wtd_std_ThermalConductivity')\n",
        "plt.ylabel('critical_temp')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFI-KSGjq73v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fix later\n",
        "sns.pairplot(x_vars=[\"wtd_mean_Valence\"], y_vars=[\"critical_temp\"], data=supercon_features, size=7)\n",
        "\n",
        "from numpy.polynomial.polynomial import polyfit\n",
        "b, m = polyfit(supercon_features['wtd_mean_Valence'], supercon_features['critical_temp'], 1)\n",
        "\n",
        "plt.plot(supercon_features['wtd_mean_Valence'], supercon_features['critical_temp'], '.')\n",
        "plt.plot(supercon_features['wtd_mean_Valence'], b + m * supercon_features['wtd_mean_Valence'], '-')\n",
        "plt.title('wtd_mean_Valence vs. critical_temp')\n",
        "plt.xlabel('wtd_mean_Valence')\n",
        "plt.ylabel('critical_temp')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQ8eD0nUm4h4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "mutual_conditional_entropies = np.zeros((16,16))\n",
        "\n",
        "for i in range(len(supercon_features.columns)):\n",
        "  ith_row = []\n",
        "  for j in range(len(supercon_features.columns)):\n",
        "\n",
        "    #conditional entropy:\n",
        "    x_given_y = metrics.mutual_info_score(supercon_features.iloc[:,i],supercon_features.iloc[:,i]) - metrics.mutual_info_score(supercon_features.iloc[:,i],supercon_features.iloc[:,j])\n",
        "    y_given_x = metrics.mutual_info_score(supercon_features.iloc[:,j],supercon_features.iloc[:,j]) - metrics.mutual_info_score(supercon_features.iloc[:,j],supercon_features.iloc[:,i])\n",
        "\n",
        "    #original entropy:\n",
        "    x_original_entropy = metrics.mutual_info_score(supercon_features.iloc[:,i],supercon_features.iloc[:,i])\n",
        "    y_original_entropy = metrics.mutual_info_score(supercon_features.iloc[:,j],supercon_features.iloc[:,j])\n",
        "\n",
        "    #mutual conditional entropy:\n",
        "    mutual_conditional_entropy = 0.5*(x_given_y/x_original_entropy) + 0.5*(y_given_x/y_original_entropy)\n",
        "    #append to ith row\n",
        "    ith_row.append(mutual_conditional_entropy)\n",
        "  mutual_conditional_entropies[i,:] = ith_row\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cprH-AajKBdC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  mutual_conditional_entropies\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwmJj3gQIBfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize = (11,9))\n",
        "sns.heatmap(mutual_conditional_entropies, xticklabels= supercon_features.columns, yticklabels=supercon_features.columns,annot=True)\n",
        "plt.show()\n",
        "\n",
        "#similar to correlation heatmap,\n",
        "# wtd_std_ThermalConductivity - 0.22\n",
        "# wtd_entropy_atomic_mass - 0.2\n",
        "# wtd_entropy_atomic_radius - 0.2\n",
        "# wtd_std_atomic_radius - 0.21\n",
        "# wtd_std_fie - 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkaA1cMhm4hC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#manually categorize critical temp into three levels: low, mid, high\n",
        "\n",
        "cut_1 = supercon.iloc[:,81].mean() - supercon.iloc[:,81].std()\n",
        "cut_2 = supercon.iloc[:,81].mean() + supercon.iloc[:,81].std()\n",
        "\n",
        "\n",
        "bins = [0, cut_1, cut_2,200]\n",
        "group_names = [0,1,2]\n",
        "supercon['critical_temp_level'] = pd.cut(supercon['critical_temp'], bins, labels=group_names)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK4dqkSeFZIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# regression analysis\n",
        "\n",
        "supercon_features = supercon_features.assign(critical_temp_level = supercon.iloc[:,82])\n",
        "\n",
        "X = supercon_features.iloc[:, [1,2, 3,4,5,6,7,8,9,10,11,12,13,14,15]].to_numpy().astype('float') #divide the data for classification purpose\n",
        "Y = supercon_features.iloc[:, 0].to_numpy().astype('int')\n",
        "\n",
        "# random sampling\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = \\\n",
        "train_test_split(X, Y, test_size=0.3, random_state=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLA3Sa7Fm4hJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use LOOCV to classify species (1-dim)\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import LeaveOneOut, KFold, cross_val_score\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "import sklearn.linear_model as skl_lm\n",
        "\n",
        "# LeaveOneOut CV linear regression\n",
        "\n",
        "regr = skl_lm.LinearRegression()\n",
        "loo = LeaveOneOut()\n",
        "loo.get_n_splits(supercon_features)\n",
        "\n",
        "regr.fit(X_train, Y_train)\n",
        "scores = list()\n",
        "\n",
        "# The mean square error\n",
        "np.mean((regr.predict(X_test) - Y_test)**2)\n",
        "\n",
        "# Explained variance score: 1 is perfect prediction and 0 means that there is no linear relationship between X and y.\n",
        "score = cross_val_score(regr, X_test, Y_test, cv=loo, scoring='neg_mean_squared_error').mean()\n",
        "\n",
        "scores.append(-score)\n",
        "scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLSOxSBVMqke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model = regr.fit(X_train, Y_train)\n",
        "prediction = regr.predict(X_test)\n",
        "r_square_score = regr.score(X_test,Y_test)\n",
        "plt.scatter(prediction,Y_test)\n",
        "plt.xlabel(\"True Critical Temp\")\n",
        "plt.ylabel(\"Predicted Critical Temp\")\n",
        "plt.title(\"Predicted values Vs. True Values\")\n",
        "plt.show()\n",
        "print(\"R square:\" + str(r_square_score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahU1ZjZQyOMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "X_train_poly = supercon_features[\"wtd_std_ThermalConductivity\"].sample(frac = 0.7)\n",
        "train_idx = X_train_poly.index.values\n",
        "test_idx = []\n",
        "for i in supercon_features.index:\n",
        "  if i not in train_idx:\n",
        "    test_idx.append(i)\n",
        "\n",
        "X_test_poly = supercon_features.iloc[test_idx].iloc[:,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btmj4jT338ao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# polynomial regression\n",
        "\n",
        "# Use LOOCV to classify species (1-dim)\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import LeaveOneOut, KFold, cross_val_score\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "import sklearn.linear_model as skl_lm\n",
        "\n",
        "p_order = np.arange(1,11)\n",
        "r_state = np.arange(0,10)\n",
        "\n",
        "# LeaveOneOut CV\n",
        "import random\n",
        "\n",
        "regr = skl_lm.LinearRegression()\n",
        "loo = LeaveOneOut()\n",
        "loo.get_n_splits(supercon_features)\n",
        "scores = list()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in p_order:\n",
        "    poly = PolynomialFeatures(i)\n",
        "    X_poly = poly.fit_transform(X_train_poly.values.reshape(-1,1))\n",
        "    score = cross_val_score(regr, X_poly, Y_train, cv=loo, scoring='neg_mean_squared_error').mean()\n",
        "    scores.append(score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia2o687gItgr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, (ax1) = plt.subplots(1, figsize=(10,4))\n",
        "\n",
        "# Note: cross_val_score() method return negative values for the scores.\n",
        "# https://github.com/scikit-learn/scikit-learn/issues/2439\n",
        "\n",
        "ax1.plot(p_order, np.array(scores)*-1, '-o')\n",
        "ax1.set_title('LOOCV')\n",
        "\n",
        "for ax in fig.axes:\n",
        "    ax.set_ylabel('Mean Squared Error')\n",
        "    ax.set_xlabel('Degree of Polynomial')\n",
        "    \n",
        "# when degree of polynomial equals 5, it reaches the elbow point, which means the model will be most efficient at poly degree equals to 5."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsD9bekTzXBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regr = skl_lm.LinearRegression()\n",
        "model = regr.fit(X_train_poly.values.reshape(-1,1), Y_train)\n",
        "prediction = regr.predict(X_test_poly.values.reshape(-1,1))\n",
        "r_square_score = regr.score(X_test_poly.values.reshape(-1,1),Y_test)\n",
        "plt.scatter(prediction,Y_test)\n",
        "plt.xlabel(\"True Critical Temp\")\n",
        "plt.ylabel(\"Predicted Critical Temp\")\n",
        "plt.title(\"Predicted values Vs. True Values\")\n",
        "plt.show()\n",
        "print(\"R square:\" + str(r_square_score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2UkFLUxCx4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# machine learning approach analysis\n",
        "\n",
        "X = supercon_features.iloc[:, [1,2, 3,4,5,6,7,8,9,10,11,12,13,14,15]].to_numpy().astype('float') #divide the data for classification purpose\n",
        "Y = supercon_features.iloc[:, 16].to_numpy().astype('int')\n",
        "\n",
        "# random sampling\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = \\\n",
        "train_test_split(X, Y, test_size=0.3, random_state=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IweToSeSm4hP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use Grid Search and Cross Validation to classify species (K-dim)\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "split=StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=100)\n",
        "for train_index, test_index in split.split(X,Y):\n",
        "    X_train_strat, Y_train_strat = X[train_index], Y[train_index]\n",
        "    X_test_strat, Y_test_strat = X[test_index], Y[test_index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8So3XPUm4hV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn.linear_model as skl_lm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.base import clone\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid=[{'n_estimators':[3, 10, 30], 'max_features':[1,2,3,4,5,6,7,8,9],'bootstrap':[True,False]}]\n",
        "tree=RandomForestClassifier()\n",
        "grid_search=GridSearchCV(tree, param_grid, cv=10, scoring='accuracy')\n",
        "grid_search.fit(X_train_strat, Y_train_strat)\n",
        "\n",
        "# Use Random Forest as our classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGFttKIEm4hb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid_search.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ABAsSmWm4hh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result=pd.DataFrame(grid_search.cv_results_['params'])\n",
        "result['accuracy']=grid_search.cv_results_['mean_test_score']\n",
        "result.sort_values('accuracy', ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCFWF4Ldm4hn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "final_model=grid_search.best_estimator_\n",
        "test_final_pred=final_model.predict(X_test_strat)\n",
        "accuracy_score(Y_test_strat, test_final_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRXT1o9Gm4ht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "test_final_pred=final_model.predict(X_test_strat)\n",
        "conf=confusion_matrix(Y_test_strat, test_final_pred)\n",
        "conf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgZ5g6zKm4h0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "\n",
        "classifier = grid_search.best_estimator_\n",
        "\n",
        "titles_options = [(\"Confusion matrix\", None),\n",
        "                  (\"Normalized confusion matrix\", 'true')]\n",
        "for title, normalize in titles_options:\n",
        "    disp = plot_confusion_matrix(classifier, X_test_strat, Y_test_strat,\n",
        "                                 display_labels=set(supercon_features[\"critical_temp_level\"].values),\n",
        "                                 cmap=plt.cm.Blues,\n",
        "                                 normalize=normalize)\n",
        "    disp.ax_.set_title(title)\n",
        "\n",
        "    print(title)\n",
        "    print(disp.confusion_matrix)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuo_Ecxtdmdu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decision_region(X, Y, model, prob=None):\n",
        "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "\n",
        "    x1, x2 = np.meshgrid(np.arange(x1_min, x1_max, 0.1),\n",
        "                         np.arange(x2_min, x2_max, 0.1))\n",
        "\n",
        "    Z = model.predict(np.c_[x1.ravel(), x2.ravel()])\n",
        "    \n",
        "    if prob is not None:\n",
        "        prob_max=model.predict_proba(np.c_[x1.ravel(), x2.ravel()]).max(1)\n",
        "        Z[prob_max<prob]=-1\n",
        "    \n",
        "    Z = Z.reshape(x1.shape)\n",
        "\n",
        "    plt.contourf(x1, x2, Z, alpha=0.4)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=Y, s=20, edgecolor='k')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1j_Q2tzc1-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Multiclass Regression (One vs Rest)\n",
        "supercon_features_valence_fie=supercon_features.iloc[:, [1,15]].to_numpy().astype('float') #  wtd_std_fie and wtd_std_thermalconductivity from corrogram\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
        "\n",
        "logit1=OneVsRestClassifier(LogisticRegression(penalty = 'none'))\n",
        "logit1.fit(supercon_features_valence_fie,Y)\n",
        "decision_region(supercon_features_valence_fie,Y,logit1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoPpf8QKYl1D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logit2=OneVsOneClassifier(LogisticRegression(penalty='none'))\n",
        "logit2.fit(supercon_features_valence_fie,Y)\n",
        "decision_region(supercon_features_valence_fie,Y,logit2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbRwBRNqfC0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#multinomial classification\n",
        "\n",
        "logit3=LogisticRegression(penalty = 'none', multi_class='multinomial')\n",
        "logit3.fit(supercon_features_valence_fie,Y)\n",
        "decision_region(supercon_features_valence_fie,Y,logit3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Upy--PQs6_hJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# svm\n",
        "def plot_svc_decision_function(model, ax=None, plot_support=True):\n",
        "    \"\"\"Plot the decision function for a 2D SVC\"\"\"\n",
        "    if ax is None:\n",
        "        ax = plt.gca()\n",
        "    xlim = ax.get_xlim()\n",
        "    ylim = ax.get_ylim()\n",
        "    \n",
        "    # create grid to evaluate model\n",
        "    x = np.linspace(xlim[0], xlim[1], 30)\n",
        "    y = np.linspace(ylim[0], ylim[1], 30)\n",
        "    Y, X = np.meshgrid(y, x)\n",
        "    xy = np.vstack([X.ravel(), Y.ravel()]).T\n",
        "    P = model.decision_function(xy).reshape(X.shape)\n",
        "    \n",
        "    # plot decision boundary and margins\n",
        "    ax.contour(X, Y, P, colors='k',\n",
        "               levels=[-1, 0, 1], alpha=0.5,\n",
        "               linestyles=['--', '-', '--'])\n",
        "    \n",
        "    # plot support vectors\n",
        "    if plot_support:\n",
        "        ax.scatter(model.support_vectors_[:, 0],\n",
        "                   model.support_vectors_[:, 1],\n",
        "                   s=300, linewidth=1, facecolors='none');\n",
        "    ax.set_xlim(xlim)\n",
        "    ax.set_ylim(ylim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvcz0ZylBdcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "critical_temp_low =((supercon_features.iloc[:, 16].to_numpy().astype('int')) == 0).astype('int') # 1 if low critical temp else 0\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
        "fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\n",
        "\n",
        "for axi, C in zip(ax, [10, 3]):\n",
        "  scale=StandardScaler()\n",
        "  X_scale=scale.fit_transform(supercon_features_valence_fie)\n",
        "  model = SVC(kernel='linear', C=C).fit(X_scale, critical_temp_low)\n",
        "  axi.scatter(X_scale[:, 0], X_scale[:, 1], c=critical_temp_low, s=50, cmap='autumn')\n",
        "  plot_svc_decision_function(model, axi)\n",
        "  axi.scatter(model.support_vectors_[:, 0],\n",
        "                model.support_vectors_[:, 1],\n",
        "                s=300, lw=1, facecolors='none');\n",
        "  axi.set_title('C = {0:.1f}'.format(C), size=14)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}